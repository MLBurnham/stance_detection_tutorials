{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed003093",
   "metadata": {},
   "source": [
    "# Stance Detection: Hyperparameter sweeps with Weights and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c47556",
   "metadata": {},
   "source": [
    "#### This tutorial demonstrates how to train a transformer with hyperparameter sweep. Our task is to classify support for Trump in a data set of tweets, and we will use a RoBERTa model that has been domain adapted for classification of political tweets.\n",
    "\n",
    "#### Requirements:\n",
    "1. A basic understanding of Python.\n",
    "2. Access to a GPU (free services like Google Colab work well).\n",
    "3. An account with Weights and Biases (https://wandb.ai/site).\n",
    "\n",
    "#### For additional resources, consult the documentation.\n",
    "Simple Transformers: https://simpletransformers.ai/docs/installation/\n",
    "\n",
    "Weights and Biases: https://docs.wandb.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda96635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from simpletransformers.classification import ClassificationArgs\n",
    "import torch\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55002da",
   "metadata": {},
   "source": [
    "#### First we need to check that we can properly communicate with the GPU. If the code prints \"Cuda available\", everything is working as expected. If you are using Google Colab and this returns CPU, then click on \"Runtime\" at the top of the page, select \"Change Runtime\", and then select \"GPU\" under \"Hardware Accelerator.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fc3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available\n",
      "PyTorch version:  1.10.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available\" if torch.cuda.is_available() is True else \"CPU\")\n",
    "print(\"PyTorch version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4470325",
   "metadata": {},
   "source": [
    "#### For this example we will use the same training and test data as in Burnham (2022). The data set consists of tweets about President Trump that are manually labeled 1: approve, 0: not approve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "573f28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('https://raw.githubusercontent.com/MLBurnham/stance_detection_tutorials/main/data/train.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/MLBurnham/stance_detection_tutorials/main/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ceb27bf",
   "metadata": {},
   "source": [
    "#### This will login to Weights and Biases so that we can send results to our account and track our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d95f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e8fc7",
   "metadata": {},
   "source": [
    "#### This chunk of code configues our sweep parameters. We can define how we want to search the hyperparameter space (bayes, grid, or random), as well as the range of parameters we want to search. If using a bayesian sweep, we can choose the performance metric we want to optimize for. In this case, I'm using a bayesian sweep to maximize MCC. \n",
    "\n",
    "#### Generally, the most important parameters to search are the number of training epochs (how many times the training data passes through the model) and the learning rate (the size of the changes implement when the models adjusts its weights and biases during training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68a2019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"mcc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"num_train_epochs\": {\"min\": 0, \"max\": 10},\n",
    "        \"learning_rate\": {\"min\": 0.0, \"max\": 5e-04 },\n",
    "    },\n",
    "#    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\":6,}, # early terminate can be used to stop runs of the model that have turned degenerate.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646e34fe",
   "metadata": {},
   "source": [
    "#### Using our configuration, we can now initialize the sweep. This will create a project on your Weights and Biases account and pass your sweep configuration to that project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c37f168b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n"
     ]
    },
    {
     "ename": "Abort",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbort\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sweep_id \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msweep_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstance_sweep\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\wandb\\sdk\\wandb_sweep.py:110\u001b[0m, in \u001b[0;36msweep\u001b[1;34m(sweep, entity, project)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Make sure we are logged in\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[43mwandb_login\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_silent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m api \u001b[38;5;241m=\u001b[39m InternalApi()\n\u001b[0;32m    112\u001b[0m sweep_id, warnings \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mupsert_sweep(sweep)\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:298\u001b[0m, in \u001b[0;36m_login\u001b[1;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning, _entity)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logged_in\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[1;32m--> 298\u001b[0m     \u001b[43mwlogin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# make sure login credentials get to the backend\u001b[39;00m\n\u001b[0;32m    301\u001b[0m wlogin\u001b[38;5;241m.\u001b[39mpropogate_login()\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:221\u001b[0m, in \u001b[0;36m_WandbLogin.prompt_api_key\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprompt_api_key\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     key, status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prompt_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m ApiKeyStatus\u001b[38;5;241m.\u001b[39mNOTTY:\n\u001b[0;32m    223\u001b[0m         directive \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb login [your_api_key]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_cli_only_mode\n\u001b[0;32m    226\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwandb.login(key=[your_api_key])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    227\u001b[0m         )\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\wandb\\sdk\\wandb_login.py:201\u001b[0m, in \u001b[0;36m_WandbLogin._prompt_api_key\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[43mapikey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_api_key\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m            \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m            \u001b[49m\u001b[43mno_offline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mno_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;66;03m# invalid key provided, try again\u001b[39;00m\n\u001b[0;32m    209\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermerror(e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\wandb\\sdk\\lib\\apikey.py:134\u001b[0m, in \u001b[0;36mprompt_api_key\u001b[1;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[0;32m    128\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermlog(\n\u001b[0;32m    129\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogging into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. (Learn how to deploy a W&B server locally: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwburls\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb_server\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m         )\n\u001b[0;32m    131\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermlog(\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can find your API key in your browser here: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/authorize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m     )\n\u001b[1;32m--> 134\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43minput_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_ask\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    135\u001b[0m write_key(settings, key, api\u001b[38;5;241m=\u001b[39mapi)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\click\\termui.py:166\u001b[0m, in \u001b[0;36mprompt\u001b[1;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 166\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\sandbox\\lib\\site-packages\\click\\termui.py:149\u001b[0m, in \u001b[0;36mprompt.<locals>.prompt_func\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hide_input:\n\u001b[0;32m    148\u001b[0m     echo(\u001b[38;5;28;01mNone\u001b[39;00m, err\u001b[38;5;241m=\u001b[39merr)\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Abort() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mAbort\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"stance_sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc81630",
   "metadata": {},
   "source": [
    "#### Next we define the specific parameters we want to use in the actual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.evaluate_during_training = True # Whether or not the model should periodically stop to evaluate performance during training\n",
    "model_args.evaluate_during_training_silent = True\n",
    "model_args.evaluate_during_training_steps = 10 # How frequently the model should stop\n",
    "model_args.manual_seed = 1 # Random seed\n",
    "model_args.max_seq_length = 512 # Max sequence length is the maximum number of tokens the model can accept. Anything beyond the max length is truncated.\n",
    "model_args.train_batch_size = 16 # The batch size is the number of examples that are passed through the model at a time. Larger batch sizes train faster, but require more VRAM on the GPU.\n",
    "model_args.eval_batch_size = 16\n",
    "model_args.train_custom_parameters_only = False\n",
    "model_args.wandb_project = \"stance_sweep\"\n",
    "# Adjust these args if you want to save local copies of the model. This is generally not recommended as models are large and many models can quickly fill all of your disk space.\n",
    "model_args.no_cache = True\n",
    "model_args.no_save = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53718727",
   "metadata": {},
   "source": [
    "#### The final step before starting the sweep is to define our training function. Within the function we choose which model we are using, pass the model and sweep configuration, and tell the model which data to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ceed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train():\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init(resume = True)\n",
    "\n",
    "    # Create a TransformerModel\n",
    "    model = ClassificationModel(\n",
    "        model_type = \"bertweet\", # Model type refers to the base version of the model. In this case we are using BERTweet, a RoBERTa model trained on Twitter data.\n",
    "        \n",
    "        # Model name refers to the specific version of the model we want to use. \n",
    "        # In this case, we are using a version of BERTweet that has been domain adapted for political tweets found here: https://huggingface.co/kornosk/polibertweet-political-twitter-roberta-mlm.\n",
    "        # You can use different models by pointing it to a different model on the huggingface model repository.\n",
    "        model_name = \"kornosk/polibertweet-political-twitter-roberta-mlm\", \n",
    "        weight = [1,3], # We're going to use weights since our data set is unbalanced, there are about three times as many not support tweets as support. This will weight missclassification of support tweets more heavily when calculating the model's loss or error.\n",
    "        use_cuda=True, # Use the GPU\n",
    "        args=model_args, # pass model arguments we defined above to the function\n",
    "        sweep_config=wandb.config, # Pass sweep configuration we defined above to the function\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.train_model(\n",
    "        train_df,\n",
    "        eval_df=test_df,\n",
    "        verbose = False,\n",
    "        accuracy=lambda truth, predictions: accuracy_score(\n",
    "            truth, [round(p) for p in predictions]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Sync with W&B\n",
    "    wandb.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3204ea7",
   "metadata": {},
   "source": [
    "#### Now we start training the model by telling the wandb agent which sweep to run, which training function to use, and how many iterations of the model it should train. Results should update in realtime on your W&B account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c757c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count = 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
