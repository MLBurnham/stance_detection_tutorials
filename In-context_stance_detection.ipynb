{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb345557",
   "metadata": {},
   "source": [
    "# Stance Detection: Classification With In-context Learners (GPT-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552ebec",
   "metadata": {},
   "source": [
    "#### This tutorial demonstrates stance detection using a few-shot approach with GPT-3. In-context learning and few-shot classification is a fast moving field and this is a relatively simple implementation. Consider this a starting point rather than a comprehensive guide. This guide will use the openai library to gain access to GPT-3 and utilize their cloud computing services. OpenAI charges based on usage and this can be fairly expensive. However, new accounts are given a small stipend to play with. This should be enough to run through this tutorial.\n",
    "\n",
    "[OpenAI Documentation](https://beta.openai.com/docs/api-reference/introduction)\n",
    "\n",
    "#### Requirements:\n",
    "1. Basic python skills\n",
    "2. An OpenAI account and API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b949f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'Insert your API key here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8154c0a2",
   "metadata": {},
   "source": [
    "For this example we will use the same training and test data as in [Burnham (2022)](https://drive.google.com/file/d/1LAbQ0zzBqXImq-Go38bSp6AqVvvYFwU0/view?usp=sharing). The data set consists of tweets about President Trump that have two sets of labels: a plain text label that is either \"support\", \"against\", or \"none\", and a corresponding binary label that is labeled 1: support, 0: against, 0: none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008bc3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stance</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'd like #TedCruz to talk more policies that d...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"the past\" and biden references obama years as...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quando mi prende lo sconforto penso che qualcu...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER think about it in ny  where most a...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GOPDebate think what #Trump2016 is saying tha...</td>\n",
       "      <td>none</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text stance  labels\n",
       "0  I'd like #TedCruz to talk more policies that d...   none     0.0\n",
       "1  \"the past\" and biden references obama years as...   none     0.0\n",
       "2  Quando mi prende lo sconforto penso che qualcu...   none     0.0\n",
       "3  @USER @USER think about it in ny  where most a...   none     0.0\n",
       "4  #GOPDebate think what #Trump2016 is saying tha...   none     0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('https://raw.githubusercontent.com/MLBurnham/stance_detection_tutorials/main/data/gpt3_train.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/MLBurnham/stance_detection_tutorials/main/data/gpt3_test.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e6daf",
   "metadata": {},
   "source": [
    "Classification with in-context learning works by treating classification as a next word prediction task. We supply the model with a prompt that consists of a description of the task and/or a few labeled examples, and a document that has a blank space where the label should be. The model then predicts what word goes in to that label space. \n",
    "\n",
    "Our first task is to generate a prompt. We'll do this by getting a random sample of labeled documents and putting them in a consistent format. Below are two helper functions to expedite this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fbffa5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_shots(df, shots, seed):\n",
    "    \"\"\"\n",
    "    A function to construct the training examples for few-shot classification. Returns a string of examples and labels\n",
    "\n",
    "    df: A data frame with 'text' and 'label' columns\n",
    "\n",
    "    shots: The number of examples to give the prompt\n",
    "\n",
    "    seed: A random seed for sampling the data frame\n",
    "    \"\"\"\n",
    "    # get a random sample from the df\n",
    "    text_sample = df.sample(n = shots, random_state = seed)\n",
    "\n",
    "    # concatenate samples together to construct a basic prompt\n",
    "    shots = ''\n",
    "    for sample, label in list(zip(text_sample['text'], text_sample['stance'])):\n",
    "        shots = shots + 'Tweet: ' + sample + '\\n' + 'Stance: ' + label + '\\n###\\n'\n",
    "\n",
    "    return shots\n",
    "\n",
    "def gen_prompt(tweet, examples):\n",
    "    \"\"\"\n",
    "    Generate a classification prompt for a few-shot model\n",
    "\n",
    "    tweet: The text of the tweet to be classified\n",
    "\n",
    "    examples: A string of training examples created by gen_shots\n",
    "    \"\"\"\n",
    "    prompt = examples + 'Tweet: ' + tweet + '\\n' + 'Stance:'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa510e8d",
   "metadata": {},
   "source": [
    "Using these functions, let's first generate a prompt template by combining and formatting 10 labeled examples. In practice, you will likely want more than 10 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc4e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate formatted and labeled examples for the prompt\n",
    "examples = gen_shots(train_df, shots = 10, seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff44aee",
   "metadata": {},
   "source": [
    "Below is what our template looks like. Documents are preceded by \"Tweet:\" and stances are preceded by \"Stance:\". Each document stance pair is separated by \"###\" and a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9fb5e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: @USER @USER where does \"doing 'the wave' with castro\" rate?\n",
      "potus obama took the fam to cuba and partied with ra√∫l, fidel's brother &amp; successor; what does one think happened to people castro didn't want obama &amp; the world to see? #demdebate HTTP\n",
      "HTTP\n",
      "Stance: none\n",
      "###\n",
      "Tweet: Remember when the national media were busy slamming @HillaryClinton for emails while giving #DonaldTrump a pass for everything? #HillaryMen\n",
      "Stance: none\n",
      "###\n",
      "Tweet: Oh come on @BBCr4today. Reason for giving Lawson unchallenged airtime on climate: it's what Trump thinks too.\n",
      "Stance: against\n",
      "###\n",
      "Tweet: @USER @USER @USER hmmm so why not even one conviction? are you incompetent, lazy or both or just blowing smoke? meanwhile, you‚Äôre taking my property without compensation: america‚Äôs hostages: #fanniegate: the long gse wail continues... HTTP\n",
      "Stance: none\n",
      "###\n",
      "Tweet: @mattyglesias There was no reason to think they wouldn't. Whereas Trump is a disaster every day so it's continually shocking people still like him.\n",
      "Stance: against\n",
      "###\n",
      "Tweet: @Colin_McManus7 2016 is the first election I can vote in and I am proudly voting for @realDonaldTrump #trumpforpresident\n",
      "Stance: support\n",
      "###\n",
      "Tweet: @JenDeplorable #pimppotus\n",
      "#FakePresident\n",
      "#Trump‚õ≥üèå\n",
      "loves you &amp; wants to grab your privates\n",
      "Stance: against\n",
      "###\n",
      "Tweet: @USER @USER @USER it means that the good people in maine need to elect @USER &amp; side step sue into retirement. #voteblue maine ü¶ûüá∫üá∏\n",
      "Stance: against\n",
      "###\n",
      "Tweet: #DonaldTrump is absolute national security threat &amp; is dangerous for America. This is behavior of inexperienced egomaniac. #Cruz no better.\n",
      "Stance: against\n",
      "###\n",
      "Tweet: #DonaldTrump &amp; #TedCruz stopped their #GOPDebate attacks only when #JebBush‚Äôs iPhone went off &amp; his #MeghanTrainor ringtone filled the hall.\n",
      "Stance: none\n",
      "###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4aef13",
   "metadata": {},
   "source": [
    "We then concatenate this prompt to each tweet we want to classify and leave the \"Stance:\" field blank. The number of prompts should be equal to the number of documents you want to classify. I will use the gen_prompt() helper function created above to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245fbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [gen_prompt(test_df['text'][i], examples) for i in range(len(test_df['text']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbed59",
   "metadata": {},
   "source": [
    "To classify the data, we then pass each prompt to GPT-3 through the OpenAI API. The code below is currently set to use the Curie model which is a smaller and cheaper version of GPT-3. To get accurate stance detection, however, you will need to use the Davinci model which is 10x more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c008448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels = [] # Create an empty list to hold the results\n",
    "for prompt in prompts:\n",
    "    res = openai.Completion.create(\n",
    "          #model=\"text-davinci-002\",\n",
    "          model = \"text-curie-001\",\n",
    "          prompt=prompt,\n",
    "          max_tokens=1, # Increase this is your label is multiple words or a multi-token word.\n",
    "          temperature=0, # Temperature controls the random variation in results.\n",
    "          #logprobs = 1, # logprobs will deterine if log probabilities for likely words are returned in addition to the label.\n",
    "          echo = False\n",
    "        )\n",
    "    labels.append(res['choices'][0]['text']) # Append the most likely label to the labels list\n",
    "    time.sleep(6) # The API is rate limited, so a short wait between documents is a good idea so that you don't get locked out of the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e67e9",
   "metadata": {},
   "source": [
    "Now that we have our labels, we can simply add them to our data frame an analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23fac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['GPT3_labs'] = labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
