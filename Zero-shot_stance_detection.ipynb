{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b905e7",
   "metadata": {},
   "source": [
    "# Stance Detection: Zero-shot NLI Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c49c53a",
   "metadata": {},
   "source": [
    "#### This tutorial demonstrations stance dection with a zero-shot NLI classifier. Our task is to classify support for Trump in a data set of tweets. To accomplish this, we will use a DeBERTa-Large model trained for natural language inference (NLI). The Transformers library will provide access to pre-trained language models as well as an easy to use pipeline for classification.\n",
    "\n",
    "Read the [Transformers documentation](https://huggingface.co/docs/transformers/index)\n",
    "\n",
    "Explore the [repository of pre-trained models](https://huggingface.co/models)\n",
    "\n",
    "#### Requirements:\n",
    "1. A very basic understanding of Python.\n",
    "2. Access to a GPU is beneficial, but not necessarily required for smaller data sets. Free services like Google Colab can be used if you don't have a desktop GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96065d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a6582",
   "metadata": {},
   "source": [
    "For this example we will use the same training and test data as in [Burnham (2022)](https://drive.google.com/file/d/1LAbQ0zzBqXImq-Go38bSp6AqVvvYFwU0/view?usp=sharing). The data set consists of tweets about President Trump that are manually labeled 1: approve, 0: not approve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8a72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('https://raw.githubusercontent.com/MLBurnham/stance_detection_tutorials/main/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a3cd7",
   "metadata": {},
   "source": [
    " he Transformers library offers a simple pipeline we can use to classify the data. All we need to do is specify the task and the model we will use. More information on the model can be found [here](https://huggingface.co/MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli)\n",
    "\n",
    "Setting the device argument to zero tells the classifier to use the GPU, and the batch_size determines how many documents are passed through the model at a time. Higher batch sizes require more memory, so try lowering the batch size if you run out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec48356",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model='MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli', device = 0, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c480038",
   "metadata": {},
   "source": [
    "Now we just prepare our data for classification by placing all of our documents in a list, and creating the hypotheses that will be used for classification. NLI classifiers work by pairing documents with \"hypotheses\" and determining if the hypothesis is true given the information in the text. \n",
    "\n",
    "To create our hypotheses we start with a basic template, in this case we use \"The author of this tweet ____ Trump.\" We then fill in the blank with possible labels, in this case \"supports\", \"opposes\", and \"does not express an opinion about.\" It's good to have a set of hypotheses that represent positive, negative, and neutral stances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0584e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(test_df['text'])\n",
    "template = 'The author of this tweet {} Trump.'\n",
    "labels = ['supports', 'opposes', 'does not express an opinion about']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9d771",
   "metadata": {},
   "source": [
    "Now we classify the data by passing our documents, labels, and template to the classifier. The model will pair each document with each of the three hypotheses:\n",
    "* The author of this tweet supports Trump.\n",
    "* The author of this tweet opposes Trump.\n",
    "* The author of this tweet does not express an opinion about Trump.\n",
    "\n",
    "It well then determine the probablility that each hypothesis is true given the document. The assigned label will be the hypothesis that is most likely to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66c018d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>zs_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump  I like Mexicans who come to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>supports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @AhmedtheBanker: Let's not forget @realDona...</td>\n",
       "      <td>0</td>\n",
       "      <td>opposes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@realDonaldTrump did not apply to immigrants o...</td>\n",
       "      <td>0</td>\n",
       "      <td>opposes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Been slacking on my @realDonaldTrump retweets....</td>\n",
       "      <td>1</td>\n",
       "      <td>supports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And how many  #latinos enemies you gained in 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>opposes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels zs_labels\n",
       "0  @realDonaldTrump  I like Mexicans who come to ...       1  supports\n",
       "1  RT @AhmedtheBanker: Let's not forget @realDona...       0   opposes\n",
       "2  @realDonaldTrump did not apply to immigrants o...       0   opposes\n",
       "3  Been slacking on my @realDonaldTrump retweets....       1  supports\n",
       "4  And how many  #latinos enemies you gained in 1...       0   opposes"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classify the documents\n",
    "res = classifier(samples, labels, hypothesis_template = template, multi_label = False)\n",
    "# return the most probable label and add it to our data frame\n",
    "test_df['zs_labels'] = [label['labels'][0] for label in res]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4722d",
   "metadata": {},
   "source": [
    "Labels are returned as plain text, so we now recode them to binary labels to evaluate classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c65885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['zs_labels'].replace(regex = {r'supports':1, r'opposes':0, r'does not express an opinion about': 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63ac28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270303800055436"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(test_df['labels'], test_df['zs_labels'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
